{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util import word_vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "text = \"\\n\".join(np.array(data['review'])).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_10000 = text[:10000]\n",
    "\n",
    "with open('data/reviews_10000.txt', 'w') as f:\n",
    "    read_data = f.write(text_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_100000 = text[:100000]\n",
    "\n",
    "with open('data/reviews_100000.txt', 'w') as f:\n",
    "    read_data = f.write(text_100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_500000 = text[:500000]\n",
    "\n",
    "with open('data/reviews_500000.txt', 'w') as f:\n",
    "    read_data = f.write(text_500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1M = text[:1000000]\n",
    "\n",
    "with open('data/reviews_1M.txt', 'w') as f:\n",
    "    read_data = f.write(text_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_5M = text[:5000000]\n",
    "\n",
    "with open('data/reviews_5M.txt', 'w') as f:\n",
    "    read_data = f.write(text_5M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_10M = text[:10000000]\n",
    "\n",
    "with open('data/reviews_10M.txt', 'w') as f:\n",
    "    read_data = f.write(text_10M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_20M = text[:20000000]\n",
    "\n",
    "with open('data/reviews_20M.txt', 'w') as f:\n",
    "    read_data = f.write(text_20M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/shakespeare.txt', 'r') as f:\n",
    "#     text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while text.find(\"<<\") != -1:\n",
    "#     ind = text.find(\"<<\")\n",
    "#     text = text[:ind-2] + text[ind+503:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/shakespeare_processed.txt', 'w') as f:\n",
    "#     f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare_processed.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_100000 = text[:100000]\n",
    "\n",
    "with open('data/shakespeare_100000.txt', 'w') as f:\n",
    "    read_data = f.write(text_100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_500000 = text[:500000]\n",
    "\n",
    "with open('data/shakespeare_500000.txt', 'w') as f:\n",
    "    read_data = f.write(text_500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1M = text[:1000000]\n",
    "\n",
    "with open('data/shakespeare_1M.txt', 'w') as f:\n",
    "    read_data = f.write(text_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_5M = text[:5000000]\n",
    "\n",
    "with open('data/shakespeare_5M.txt', 'w') as f:\n",
    "    read_data = f.write(text_5M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10439762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/finnish.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1M = text[:1000000]\n",
    "\n",
    "with open('data/finnish_1M.txt', 'w') as f:\n",
    "    read_data = f.write(text_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_5M = text[:5000000]\n",
    "\n",
    "with open('data/finnish_5M.txt', 'w') as f:\n",
    "    read_data = f.write(text_5M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "le101",
   "language": "python",
   "name": "le101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
